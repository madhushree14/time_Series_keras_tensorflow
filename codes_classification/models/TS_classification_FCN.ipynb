{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "liberal-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prospective-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm = '1037_L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(alarm_name):\n",
    "    \"\"\" Returns a dataset of all valve values and specific alarm column.\"\"\"\n",
    "    \n",
    "    dfs = {file.split(\"_\")[-4]: pd.read_pickle(file) for file in \\\n",
    "           glob.glob(\"S:\\SRH\\BDBA_Sem_2\\Case_study_1\\data\\*.pkl\")}\n",
    "    \n",
    "    dfs_sorted = dict(sorted(dfs.items()))\n",
    "    df_single = pd.concat(dfs_sorted, axis=0)\n",
    "    \n",
    "    alarms = ['1031_H', '1031_L', '1034_H', '1034_L', '1037_H', '1037_L']\n",
    "    alarms.remove(alarm_name)\n",
    "    \n",
    "    df_alarm = df_single.drop(alarms, axis=1)\n",
    "    df_alarm.fillna(0, inplace=True)\n",
    "    \n",
    "    return df_alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alarm = create_df(alarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_sequence(data, past_seq_len, future_window):\n",
    "    \"\"\" Creates a small input sequence of a given seq length and \n",
    "        returns two numpy arrays as input and output sequence\n",
    "        \n",
    "        Args:\n",
    "        data: input dataframe\n",
    "        past_seq_len: integer number\n",
    "        future_window: integer number\n",
    "\n",
    "        \"\"\"\n",
    "    target_df = data.iloc[:,-1]\n",
    "    input_x = []\n",
    "    output_y = []\n",
    "    for i in range(len(data) - past_seq_len -1):\n",
    "        ins = data.iloc[i:(i+past_seq_len), 0:data.shape[1]-1]\n",
    "        ots = np.where((target_df.iloc[(i+past_seq_len):(i+past_seq_len+future_window)]>0).any(), 1, 0)\n",
    "        input_x.append(ins)\n",
    "        output_y.append(ots)\n",
    "    in_array = np.array(input_x).astype(np.float32)\n",
    "    out_array = np.array(output_y).astype(np.float32)\n",
    "    \n",
    "    return in_array, out_array.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessed_df(df, val_pct):\n",
    "    \"\"\" Creates train, validation and test set after applying normalisation of all feature cols\n",
    "    Args:\n",
    "    df: dataframe object\n",
    "    val_pct: percentage size of validation plus test size (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    test_data_size = round(df.shape[0] * val_pct)\n",
    "    \n",
    "    train_data = df[:-test_data_size]\n",
    "    test_data = df[-test_data_size:]\n",
    "    \n",
    "    # Scaling the data\n",
    "    scalar = MinMaxScaler()\n",
    "    scalar.fit(train_data.iloc[:,:-1])\n",
    "    # save the scaler\n",
    "    dump(scalar, open('model_objects\\scaler_cls_fcn'+alarm+'.pkl', 'wb'))\n",
    "    \n",
    "    train_scaled = scalar.transform(train_data.iloc[:,:-1]) \n",
    "    test_scaled = scalar.transform(test_data.iloc[:,:-1])\n",
    "    \n",
    "    df_train = pd.DataFrame(train_scaled)\n",
    "    df_train['alarm'] = train_data.iloc[:,-1].values\n",
    "    df_test = pd.DataFrame(test_scaled)\n",
    "    df_test['alarm'] = test_data.iloc[:,-1].values\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = preprocessed_df(df_alarm, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the window size\n",
    "n_steps = 15\n",
    "future_window = 10\n",
    "\n",
    "# split into samples\n",
    "X_train, y_train = input_sequence(df_train, n_steps, future_window)\n",
    "X_test, y_test = input_sequence(df_test, n_steps, future_window)\n",
    "\n",
    "nb_classes = len(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape + (1,))\n",
    "X_test = X_test.reshape(X_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = min(X_train.shape[0]/10, 16)\n",
    "nb_epochs = 50\n",
    "\n",
    "x = keras.layers.Input(X_train.shape[1:])\n",
    "\n",
    "#drop_out = Dropout(0.2)(x)\n",
    "conv1 = keras.layers.Conv2D(128, 8, 1, padding='same')(x)\n",
    "conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation('relu')(conv1)\n",
    "    \n",
    "#drop_out = Dropout(0.2)(conv1)\n",
    "conv2 = keras.layers.Conv2D(256, 5, 1, padding='same')(conv1)\n",
    "conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "conv2 = keras.layers.Activation('relu')(conv2)\n",
    "    \n",
    "#drop_out = Dropout(0.2)(conv2)\n",
    "conv3 = keras.layers.Conv2D(128, 3, 1, padding='same')(conv2)\n",
    "conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "conv3 = keras.layers.Activation('relu')(conv3)\n",
    "    \n",
    "full = keras.layers.GlobalAveragePooling2D()(conv3)\n",
    "out = keras.layers.Dense(nb_classes, activation='sigmoid')(full)\n",
    "\n",
    "model = keras.models.Model(inputs=x, outputs=out)\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "#callback function earlystopping\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'loss', factor=0.5,\n",
    "                      patience=15, min_lr=0.0001)\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epochs,\n",
    "              verbose=1, validation_data=(X_test, y_test), callbacks = [reduce_lr])\n",
    "#Print the testing results which has the lowest training loss.\n",
    "log = pd.DataFrame(hist.history)\n",
    "print(log.loc[log['loss'].idxmin]['loss'], log.loc[log['loss'].idxmin]['val_acc'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

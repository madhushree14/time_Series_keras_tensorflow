{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beneficial-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "# from torch import nn, optim\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "least-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "valves = [\"20-LV-1031_Z_X_Value\", \"20-LV-1031_Z_Y_Value\", \"20-LV-1034_Z_X_Value\",\n",
    "              \"20-LV-1034_Z_Y_Value\", \"20-PV-1037_Z_X_Value\", \"20-PV-1037_Z_Y_Value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weekly-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "valve = '20-PV-1037_Z_Y_Value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "still-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(valve_name):\n",
    "    \"\"\" Returns a dataset of specific valve column.\"\"\"\n",
    "    \n",
    "    dfs = {file.split(\"_\")[-4]: pd.read_pickle(file) for file in \\\n",
    "           glob.glob(\"S:\\SRH\\BDBA_Sem_2\\Case_study_1\\data\\*.pkl\")}\n",
    "    \n",
    "    dfs_sorted = dict(sorted(dfs.items()))\n",
    "    df_single = pd.concat(dfs_sorted, axis=0)\n",
    "\n",
    "    valve_df = df_single.filter([valve_name])\n",
    "    valve_df = valve_df.droplevel(0, axis=0)\n",
    "    return valve_df\n",
    "\n",
    "valve_1_df = create_df(valve)\n",
    "\n",
    "def preprocessed_df(df, val_pct):\n",
    "    \"\"\" Creates train, validation and test set after applying normalisation of all feature cols\n",
    "    Args:\n",
    "    df: dataframe object\n",
    "    val_pct: percentage size of validation plus test size (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    val_data_size = round(df.shape[0] * 0.3)\n",
    "    test_data_size = round(val_data_size * 0.1)\n",
    "    \n",
    "    train_data = df[:-val_data_size]\n",
    "    val_data = df[-val_data_size:-test_data_size]\n",
    "    test_data = df[-test_data_size:]\n",
    "    \n",
    "    # Scaling the data\n",
    "    scalar = MinMaxScaler()\n",
    "    scalar.fit(train_data.values.reshape(-1,1)) # sklearn scalars accepts 2d arrays to scale hence reshaping the data\n",
    "    # save the scaler\n",
    "    dump(scalar, open(f'model_objects_hybrid\\scaler_hybrid_{valve}.pkl', 'wb'))\n",
    "\n",
    "    train_scaled = scalar.transform(train_data.values.reshape(-1,1)) # pandas does'nt have .reshape() hence by calling the values and then applying underlying numpy reshape\n",
    "    val_scaled = scalar.transform(val_data.values.reshape(-1,1))\n",
    "    test_scaled = scalar.transform(test_data.values.reshape(-1,1))\n",
    "\n",
    "    df_train = pd.DataFrame(train_scaled)\n",
    "    df_val = pd.DataFrame(val_scaled)\n",
    "    df_test = pd.DataFrame(test_scaled)\n",
    "    \n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "df_train, df_val, df_test = preprocessed_df(valve_1_df, 0.3)\n",
    "\n",
    "# Creating small input sequences\n",
    "def input_sequence(data, seq_len):\n",
    "    \"\"\" Creates a small input sequence of a given seq length and \n",
    "        returns two numpy arrays asinpuy and output sequence\n",
    "        \n",
    "        Args:\n",
    "        data = input dataframe\n",
    "        seq_len = integer number\n",
    "\n",
    "        \"\"\"\n",
    "    input_x = []\n",
    "    output_y = []\n",
    "    \n",
    "    for i in range(len(data)-seq_len-1):\n",
    "        in_x = data[i:(i+seq_len)]\n",
    "        out_y = data[i+seq_len]\n",
    "        \n",
    "        input_x.append(in_x)\n",
    "        output_y.append(out_y)\n",
    "    \n",
    "    return np.array(input_x), np.array(output_y)\n",
    "\n",
    "train_values = df_train.values.astype('float32')\n",
    "val_values = df_val.values.astype('float32')\n",
    "test_values = df_test.values.astype('float32')\n",
    "# specify the window size\n",
    "n_steps = 15\n",
    "# split into samples\n",
    "X_train, y_train = input_sequence(train_values, n_steps)\n",
    "X_val, y_val = input_sequence(val_values, n_steps)\n",
    "X_test, y_test = input_sequence(test_values, n_steps)\n",
    "# reshape into [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "attached-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv1D(filters=32, kernel_size=5,strides=1, padding=\"causal\",activation=\"relu\",\n",
    "                                                   input_shape=[None, 1]),\n",
    "                                                   tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "                                                   tf.keras.layers.LSTM(64, return_sequences=True),  \n",
    "                                                   tf.keras.layers.Dense(30, activation=\"relu\"),  \n",
    "                                                   tf.keras.layers.Dense(10, activation=\"relu\"),  \n",
    "                                                   tf.keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "banner-dealing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "522/522 - 13s - loss: 0.1174 - mae: 0.4120 - val_loss: 0.0452 - val_mae: 0.2484\n",
      "Epoch 2/100\n",
      "522/522 - 8s - loss: 0.0554 - mae: 0.2586 - val_loss: 0.0223 - val_mae: 0.1821\n",
      "Epoch 3/100\n",
      "522/522 - 8s - loss: 0.0369 - mae: 0.2267 - val_loss: 0.0180 - val_mae: 0.1640\n",
      "Epoch 4/100\n",
      "522/522 - 8s - loss: 0.0317 - mae: 0.2235 - val_loss: 0.0181 - val_mae: 0.1604\n",
      "Epoch 5/100\n",
      "522/522 - 8s - loss: 0.0303 - mae: 0.2233 - val_loss: 0.0187 - val_mae: 0.1611\n",
      "Epoch 6/100\n",
      "522/522 - 8s - loss: 0.0299 - mae: 0.2234 - val_loss: 0.0192 - val_mae: 0.1634\n",
      "Epoch 7/100\n",
      "522/522 - 8s - loss: 0.0298 - mae: 0.2235 - val_loss: 0.0195 - val_mae: 0.1648\n",
      "Epoch 8/100\n",
      "522/522 - 8s - loss: 0.0298 - mae: 0.2235 - val_loss: 0.0196 - val_mae: 0.1655\n",
      "Epoch 9/100\n",
      "522/522 - 9s - loss: 0.0297 - mae: 0.2234 - val_loss: 0.0197 - val_mae: 0.1659\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "es = EarlyStopping(monitor='val_loss', patience=6)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=2, \n",
    "                            validation_data=(X_val, y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "changing-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file\n",
    "model.save(f'model_time_series_hybrid_{valve}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "healthy-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'S:\\SRH\\caseStudy1\\Codes\\codes_timeSeries\\model_time_series_hybrid_{valve}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "thorough-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the scaler\n",
    "# scalar = load(open(f'S:\\SRH\\caseStudy1\\Codes\\codes_timeSeries\\model_objects_hybrid\\scaler_hybrid_{valve}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "genetic-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.021, RMSE: 0.145, MAE: 0.171\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "mse, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (mse, sqrt(mse), mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-fashion",
   "metadata": {},
   "source": [
    "MSE: 0.008, RMSE: 0.090, MAE: 0.094 for '20-LV-1031_Z_X_Value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-cabinet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
